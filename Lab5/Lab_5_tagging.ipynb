{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import glob\n",
    "import regex\n",
    "from collections import Counter, OrderedDict, defaultdict\n",
    "import numpy as np\n",
    "import math\n",
    "import regex\n",
    "import requests\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Download docker image of KRNNT2. It includes the following tools:\n",
    "- Morfeusz2 - morphological dictionary\n",
    "- Corpus2 - corpus access library\n",
    "- Toki - tokenizer for Polish\n",
    "- Maca - morphosyntactic analyzer\n",
    "- KRNNT - Polish tagger\n",
    "\n",
    "# 2. As an alternative you can use Tagger interfaces in Clarin-Pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1179"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = [f for f in glob.glob('../ustawy/*')]\n",
    "\n",
    "\n",
    "def read_file(filename):\n",
    "    with open(filename, encoding='UTF-8') as f:\n",
    "        text = f.read()\n",
    "        return text.lower()\n",
    "\n",
    "\n",
    "files_content = pd.DataFrame({\n",
    "    \"id\": [Path(filename).stem for filename in files],\n",
    "    \"text\": [read_file(filename) for filename in files]\n",
    "})\n",
    "len(files_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Use the tool to tag and lemmatize the law corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def krnnt2(text):\n",
    "    response = requests.post(\"http://localhost:9200\", data=text.encode(\"utf-8\"))\n",
    "    return response.content.decode(\"utf-8\")\n",
    "\n",
    "\n",
    "# files_content[\"tagged\"] = [krnnt2(text) for text in tqdm(files_content[\"text\"], total=1179)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files_content.to_csv(\"files_tagged.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>tagged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1993_599</td>\n",
       "      <td>\\n\\n\\n\\ndz.u. z 1993 r. nr 129, poz. 599 \\n   ...</td>\n",
       "      <td>dz\\tnone\\n\\tdziennik\\tbrev:pun\\tdisamb\\n.\\tnon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1993_602</td>\n",
       "      <td>\\n\\n\\n\\ndz.u. z 1993 r. nr 129, poz. 602 \\n   ...</td>\n",
       "      <td>dz\\tnone\\n\\tdziennik\\tbrev:pun\\tdisamb\\n.\\tnon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1993_645</td>\n",
       "      <td>\\n\\n\\n\\ndz.u. z 1993 r. nr 134, poz. 645\\n    ...</td>\n",
       "      <td>dz\\tnone\\n\\tdziennik\\tbrev:pun\\tdisamb\\n.\\tnon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1993_646</td>\n",
       "      <td>\\n\\n\\n\\ndz.u. z 1993 r. nr 134, poz. 646\\n    ...</td>\n",
       "      <td>dz\\tnone\\n\\tdziennik\\tbrev:pun\\tdisamb\\n.\\tnon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1994_150</td>\n",
       "      <td>\\n\\n\\n\\ndz.u. z 1994 r. nr 40, poz. 150\\n     ...</td>\n",
       "      <td>dz\\tnone\\n\\tdziennik\\tbrev:pun\\tdisamb\\n.\\tnon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>2004_96</td>\n",
       "      <td>\\n\\n\\ntekst ustawy\\nprzyjęty przez senat bez p...</td>\n",
       "      <td>tekst\\tnone\\n\\ttekst\\tsubst:sg:nom:m3\\tdisamb\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>2004_962</td>\n",
       "      <td>\\n\\n\\ntekst ustawy\\nprzyjęty przez senat bez p...</td>\n",
       "      <td>tekst\\tnone\\n\\ttekst\\tsubst:sg:nom:m3\\tdisamb\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>2004_963</td>\n",
       "      <td>\\n\\n\\n\\ndz.u. z 2004 r. nr 97, poz. 963\\n     ...</td>\n",
       "      <td>dz\\tnone\\n\\tdziennik\\tbrev:pun\\tdisamb\\n.\\tnon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1177</th>\n",
       "      <td>2004_964</td>\n",
       "      <td>\\n\\n\\ntekst ustawy przyjęty przez senat bez po...</td>\n",
       "      <td>tekst\\tnone\\n\\ttekst\\tsubst:sg:nom:m3\\tdisamb\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>2004_97</td>\n",
       "      <td>\\n\\n\\n\\ndz.u. z 2004 r. nr 11, poz. 97\\n      ...</td>\n",
       "      <td>dz\\tnone\\n\\tdziennik\\tbrev:pun\\tdisamb\\n.\\tnon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1179 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                               text  \\\n",
       "0     1993_599  \\n\\n\\n\\ndz.u. z 1993 r. nr 129, poz. 599 \\n   ...   \n",
       "1     1993_602  \\n\\n\\n\\ndz.u. z 1993 r. nr 129, poz. 602 \\n   ...   \n",
       "2     1993_645  \\n\\n\\n\\ndz.u. z 1993 r. nr 134, poz. 645\\n    ...   \n",
       "3     1993_646  \\n\\n\\n\\ndz.u. z 1993 r. nr 134, poz. 646\\n    ...   \n",
       "4     1994_150  \\n\\n\\n\\ndz.u. z 1994 r. nr 40, poz. 150\\n     ...   \n",
       "...        ...                                                ...   \n",
       "1174   2004_96  \\n\\n\\ntekst ustawy\\nprzyjęty przez senat bez p...   \n",
       "1175  2004_962  \\n\\n\\ntekst ustawy\\nprzyjęty przez senat bez p...   \n",
       "1176  2004_963  \\n\\n\\n\\ndz.u. z 2004 r. nr 97, poz. 963\\n     ...   \n",
       "1177  2004_964  \\n\\n\\ntekst ustawy przyjęty przez senat bez po...   \n",
       "1178   2004_97  \\n\\n\\n\\ndz.u. z 2004 r. nr 11, poz. 97\\n      ...   \n",
       "\n",
       "                                                 tagged  \n",
       "0     dz\\tnone\\n\\tdziennik\\tbrev:pun\\tdisamb\\n.\\tnon...  \n",
       "1     dz\\tnone\\n\\tdziennik\\tbrev:pun\\tdisamb\\n.\\tnon...  \n",
       "2     dz\\tnone\\n\\tdziennik\\tbrev:pun\\tdisamb\\n.\\tnon...  \n",
       "3     dz\\tnone\\n\\tdziennik\\tbrev:pun\\tdisamb\\n.\\tnon...  \n",
       "4     dz\\tnone\\n\\tdziennik\\tbrev:pun\\tdisamb\\n.\\tnon...  \n",
       "...                                                 ...  \n",
       "1174  tekst\\tnone\\n\\ttekst\\tsubst:sg:nom:m3\\tdisamb\\...  \n",
       "1175  tekst\\tnone\\n\\ttekst\\tsubst:sg:nom:m3\\tdisamb\\...  \n",
       "1176  dz\\tnone\\n\\tdziennik\\tbrev:pun\\tdisamb\\n.\\tnon...  \n",
       "1177  tekst\\tnone\\n\\ttekst\\tsubst:sg:nom:m3\\tdisamb\\...  \n",
       "1178  dz\\tnone\\n\\tdziennik\\tbrev:pun\\tdisamb\\n.\\tnon...  \n",
       "\n",
       "[1179 rows x 3 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# files_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>tagged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1993_599</td>\n",
       "      <td>\\n\\n\\n\\ndz.u. z 1993 r. nr 129, poz. 599 \\n   ...</td>\n",
       "      <td>dz\\tnone\\n\\tdziennik\\tbrev:pun\\tdisamb\\n.\\tnon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1993_602</td>\n",
       "      <td>\\n\\n\\n\\ndz.u. z 1993 r. nr 129, poz. 602 \\n   ...</td>\n",
       "      <td>dz\\tnone\\n\\tdziennik\\tbrev:pun\\tdisamb\\n.\\tnon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1993_645</td>\n",
       "      <td>\\n\\n\\n\\ndz.u. z 1993 r. nr 134, poz. 645\\n    ...</td>\n",
       "      <td>dz\\tnone\\n\\tdziennik\\tbrev:pun\\tdisamb\\n.\\tnon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1993_646</td>\n",
       "      <td>\\n\\n\\n\\ndz.u. z 1993 r. nr 134, poz. 646\\n    ...</td>\n",
       "      <td>dz\\tnone\\n\\tdziennik\\tbrev:pun\\tdisamb\\n.\\tnon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1994_150</td>\n",
       "      <td>\\n\\n\\n\\ndz.u. z 1994 r. nr 40, poz. 150\\n     ...</td>\n",
       "      <td>dz\\tnone\\n\\tdziennik\\tbrev:pun\\tdisamb\\n.\\tnon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>1174</td>\n",
       "      <td>2004_96</td>\n",
       "      <td>\\n\\n\\ntekst ustawy\\nprzyjęty przez senat bez p...</td>\n",
       "      <td>tekst\\tnone\\n\\ttekst\\tsubst:sg:nom:m3\\tdisamb\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>1175</td>\n",
       "      <td>2004_962</td>\n",
       "      <td>\\n\\n\\ntekst ustawy\\nprzyjęty przez senat bez p...</td>\n",
       "      <td>tekst\\tnone\\n\\ttekst\\tsubst:sg:nom:m3\\tdisamb\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>1176</td>\n",
       "      <td>2004_963</td>\n",
       "      <td>\\n\\n\\n\\ndz.u. z 2004 r. nr 97, poz. 963\\n     ...</td>\n",
       "      <td>dz\\tnone\\n\\tdziennik\\tbrev:pun\\tdisamb\\n.\\tnon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1177</th>\n",
       "      <td>1177</td>\n",
       "      <td>2004_964</td>\n",
       "      <td>\\n\\n\\ntekst ustawy przyjęty przez senat bez po...</td>\n",
       "      <td>tekst\\tnone\\n\\ttekst\\tsubst:sg:nom:m3\\tdisamb\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>1178</td>\n",
       "      <td>2004_97</td>\n",
       "      <td>\\n\\n\\n\\ndz.u. z 2004 r. nr 11, poz. 97\\n      ...</td>\n",
       "      <td>dz\\tnone\\n\\tdziennik\\tbrev:pun\\tdisamb\\n.\\tnon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1179 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0        id                                               text  \\\n",
       "0              0  1993_599  \\n\\n\\n\\ndz.u. z 1993 r. nr 129, poz. 599 \\n   ...   \n",
       "1              1  1993_602  \\n\\n\\n\\ndz.u. z 1993 r. nr 129, poz. 602 \\n   ...   \n",
       "2              2  1993_645  \\n\\n\\n\\ndz.u. z 1993 r. nr 134, poz. 645\\n    ...   \n",
       "3              3  1993_646  \\n\\n\\n\\ndz.u. z 1993 r. nr 134, poz. 646\\n    ...   \n",
       "4              4  1994_150  \\n\\n\\n\\ndz.u. z 1994 r. nr 40, poz. 150\\n     ...   \n",
       "...          ...       ...                                                ...   \n",
       "1174        1174   2004_96  \\n\\n\\ntekst ustawy\\nprzyjęty przez senat bez p...   \n",
       "1175        1175  2004_962  \\n\\n\\ntekst ustawy\\nprzyjęty przez senat bez p...   \n",
       "1176        1176  2004_963  \\n\\n\\n\\ndz.u. z 2004 r. nr 97, poz. 963\\n     ...   \n",
       "1177        1177  2004_964  \\n\\n\\ntekst ustawy przyjęty przez senat bez po...   \n",
       "1178        1178   2004_97  \\n\\n\\n\\ndz.u. z 2004 r. nr 11, poz. 97\\n      ...   \n",
       "\n",
       "                                                 tagged  \n",
       "0     dz\\tnone\\n\\tdziennik\\tbrev:pun\\tdisamb\\n.\\tnon...  \n",
       "1     dz\\tnone\\n\\tdziennik\\tbrev:pun\\tdisamb\\n.\\tnon...  \n",
       "2     dz\\tnone\\n\\tdziennik\\tbrev:pun\\tdisamb\\n.\\tnon...  \n",
       "3     dz\\tnone\\n\\tdziennik\\tbrev:pun\\tdisamb\\n.\\tnon...  \n",
       "4     dz\\tnone\\n\\tdziennik\\tbrev:pun\\tdisamb\\n.\\tnon...  \n",
       "...                                                 ...  \n",
       "1174  tekst\\tnone\\n\\ttekst\\tsubst:sg:nom:m3\\tdisamb\\...  \n",
       "1175  tekst\\tnone\\n\\ttekst\\tsubst:sg:nom:m3\\tdisamb\\...  \n",
       "1176  dz\\tnone\\n\\tdziennik\\tbrev:pun\\tdisamb\\n.\\tnon...  \n",
       "1177  tekst\\tnone\\n\\ttekst\\tsubst:sg:nom:m3\\tdisamb\\...  \n",
       "1178  dz\\tnone\\n\\tdziennik\\tbrev:pun\\tdisamb\\n.\\tnon...  \n",
       "\n",
       "[1179 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_content = pd.read_csv(\"files_tagged.csv\")\n",
    "f_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_content = f_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. For example: \"Ala ma kota\", which is tagged as: \n",
    "```\n",
    "Ala\tnone\n",
    "        Ala\tsubst:sg:nom:f\tdisamb\n",
    "ma\tspace\n",
    "        mieć\tfin:sg:ter:imperf\tdisamb\n",
    "kota\tspace\n",
    "        kot\tsubst:sg:acc:m2\tdisamb\n",
    ".\tnone\n",
    "        .\tinterp\tdisamb\n",
    "```\n",
    "the algorithm should return the following bigrams: `ala:subst mieć:fin` and `mieć:fin kot:subst`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Miła\tnone\n",
      "\tmiła\tsubst:sg:nom:f\tdisamb\n",
      "ma\tspace\n",
      "\tmieć\tfin:sg:ter:imperf\tdisamb\n",
      ",\tnone\n",
      "\t,\tinterp\tdisamb\n",
      "jak\tspace\n",
      "\tjak\tadv:pos\tdisamb\n",
      "żyć\tspace\n",
      "\tżyć\tinf:imperf\tdisamb\n",
      "?\tnone\n",
      "\t?\tinterp\tdisamb\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " 'Miła\\tnone\\n\\tmiła\\tsubst:sg:nom:f\\tdisamb\\nma\\tspace\\n\\tmieć\\tfin:sg:ter:imperf\\tdisamb\\n,\\tnone\\n\\t,\\tinterp\\tdisamb\\njak\\tspace\\n\\tjak\\tadv:pos\\tdisamb\\nżyć\\tspace\\n\\tżyć\\tinf:imperf\\tdisamb\\n?\\tnone\\n\\t?\\tinterp\\tdisamb\\n\\n')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# response = requests.post(\"http://localhost:9200\", data=\"Ala ma kota, a żółty Kot ma Ale.\".encode(\"UTF-8\"))\n",
    "response = requests.post(\"http://localhost:9200\", data=\"Miła ma, jak żyć?\".encode(\"UTF-8\"))\n",
    "decoded = response.content.decode(\"UTF-8\")\n",
    "print(decoded), decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stats = Counter()\n",
    "test = krnnt2(\"Ala ma kota.\")\n",
    "lines = test.split(\"\\n\")\n",
    "\n",
    "# zmiana planów.\n",
    "tmp = []\n",
    "for line in lines:\n",
    "    if line.startswith(\"\\t\"): # bierzemy tylko linie ktore zaczynaja sie od wcięcia \\t bo one mają zlematyzowane elementy.\n",
    "        tmp.append(line)\n",
    "\n",
    "texts = files_content\n",
    "bigrams = zip(tmp[:-1], tmp[1:])\n",
    "\n",
    "#iterujemy po kazdym bigramie i zliczamy\n",
    "for l1, l2 in list(bigrams):\n",
    "    tokens_first = l1.split(\"\\t\")\n",
    "    word = tokens_first[1].lower()\n",
    "    morph_cat = tokens_first[2].split(\":\")[0]\n",
    "    lem_morph1 = word + \":\" + morph_cat\n",
    "\n",
    "    tokens_second = l2.split(\"\\t\")\n",
    "    word = tokens_second[1].lower()\n",
    "    morph_cat = tokens_second[2].split(\":\")[0]\n",
    "    lem_morph2 = word + \":\" + morph_cat\n",
    "\n",
    "    full_name = lem_morph1 + \" & \" + lem_morph2\n",
    "    test_stats[full_name] += 1\n",
    "\n",
    "test_stats_clean = test_stats\n",
    "for bigram, count in list(test_stats.items()):\n",
    "    # print(bigram)\n",
    "    w1, w2 = bigram.split(\" & \")\n",
    "    lem1 = w1.split(\":\")[0]\n",
    "    lem2 = w2.split(\":\")[0]\n",
    "    found1 = regex.findall(r'\\p{L}+', lem1, flags=regex.IGNORECASE)\n",
    "    found2 = regex.findall(r'\\p{L}+', lem2, flags=regex.IGNORECASE)\n",
    "\n",
    "    if not found1 or not found2:\n",
    "        del test_stats_clean[bigram]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'ala:subst & mieć:fin': 1, 'mieć:fin & kot:subst': 1})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_stats_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Using the tagged corpus compute bigram statistic for the tokens containing:\n",
    "- lemmatized, downcased word\n",
    "- morphosyntactic category of the word (subst, fin, adj, etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sprawdź czy są podziały po 2 lub więcej wyników...\n",
    "czy_bylo_wiecej_niz_raz = False\n",
    "for index, row in files_content.iterrows():\n",
    "    lines = row[\"tagged\"].split(\"\\n\")\n",
    "    \n",
    "    # jeżeli mamy linie typu:\n",
    "    '''\n",
    "     ma\tspace\n",
    "         mieć\tfin:sg:ter:imperf\n",
    "         mój  \tadj:sg:nom:f:pos\n",
    "         mój  \tadj:sg:voc:f:pos\n",
    "    '''\n",
    "    # to musimy sprawdzać czy zaczyna się coś na \\t i sprawdzać \\n\n",
    "    cnt = 0 \n",
    "    for line in lines:\n",
    "        is_lem = line.startswith(\"\\t\")\n",
    "        if is_lem: # jeżeli linia zaczyna się od \\t czyli jest wyczyszczona to dodaj 1\n",
    "            cnt += 1\n",
    "        else: # jeżeli nie to wyczysc licznik, bo wtedy mamy kolejne słowo\n",
    "            cnt = 0 \n",
    "\n",
    "        if cnt > 1: #jeżeli licznik jest wiekszy niz 1 to znaczy ze są podwoje słowa, oznacz flage.\n",
    "            czy_bylo_wiecej_niz_raz = True\n",
    "czy_bylo_wiecej_niz_raz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_stats = Counter()\n",
    "single_stats = Counter()\n",
    "for index, row in files_content.iterrows():\n",
    "    lines = row[\"tagged\"].split(\"\\n\")\n",
    "   \n",
    "    tmp = []\n",
    "    for line in lines:\n",
    "        if line.startswith(\"\\t\"): # bierzemy tylko linie ktore zaczynaja sie od wcięcia \\t bo one mają zlematyzowane elementy.\n",
    "            tmp.append(line)\n",
    "    \n",
    "\n",
    "    for single_line in tmp:\n",
    "        single = single_line.split(\"\\t\")\n",
    "        word = single[1].lower()\n",
    "        morph_cat = single[2].split(\":\")[0]\n",
    "        lem_morph_single = word + \":\" + morph_cat\n",
    "        single_stats[lem_morph_single] += 1\n",
    "\n",
    "\n",
    "    texts = files_content\n",
    "    # zmiana planów. samo zip nie wystarczy, bo czasami zwracane jest kilka linijek z \\t do jednego słowa.\n",
    "    bigrams = zip(tmp[:-1], tmp[1:])\n",
    "\n",
    "    #iterujemy po kazdym bigramie i zliczamy\n",
    "    for l1, l2 in list(bigrams):\n",
    "        tokens_first = l1.split(\"\\t\")\n",
    "        word = tokens_first[1].lower()\n",
    "        morph_cat = tokens_first[2].split(\":\")[0]\n",
    "        lem_morph1 = word + \":\" + morph_cat\n",
    "\n",
    "        tokens_second = l2.split(\"\\t\")\n",
    "        word = tokens_second[1].lower()\n",
    "        morph_cat = tokens_second[2].split(\":\")[0]\n",
    "        lem_morph2 = word + \":\" + morph_cat\n",
    "\n",
    "        full_name = lem_morph1 + \" & \" + lem_morph2\n",
    "        bigrams_stats[full_name] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wersja ze sprawdzaniem czy są nowe linie...\n",
    "bigrams_stats_add = Counter()\n",
    "for index, row in files_content.iterrows():\n",
    "    all_lines = row[\"tagged\"].split(\"\\n\")\n",
    "\n",
    "    grouped_lines = []\n",
    "    tmp = []\n",
    "    for id, line in enumerate(all_lines):\n",
    "        if line.startswith(\"\\t\"):\n",
    "            tmp.append(line)\n",
    "        else:\n",
    "            if len(tmp) > 0:\n",
    "                grouped_lines.append(tmp)\n",
    "            tmp = []\n",
    "\n",
    "\n",
    "    for ind, line_group in enumerate(grouped_lines):\n",
    "        if (0 <= ind+1 < len(grouped_lines)) and (len(line_group) > 1 or len(grouped_lines[ind+1]) > 1):\n",
    "            bigrams = zip(line_group[:-1], line_group[1:])\n",
    "        else:\n",
    "            bigrams = zip(grouped_lines[ind-1], line_group)\n",
    "\n",
    "        #iterujemy po kazdym bigramie i zliczamy\n",
    "        for l1, l2 in list(bigrams):\n",
    "            tokens_first = l1.split(\"\\t\")\n",
    "            word = tokens_first[1].lower()\n",
    "            morph_cat = tokens_first[2].split(\":\")[0]\n",
    "            lem_morph1 = word + \":\" + morph_cat\n",
    "\n",
    "            tokens_second = l2.split(\"\\t\")\n",
    "            word = tokens_second[1].lower()\n",
    "            morph_cat = tokens_second[2].split(\":\")[0]\n",
    "            lem_morph2 = word + \":\" + morph_cat\n",
    "\n",
    "            full_name = lem_morph1 + \" & \" + lem_morph2\n",
    "            bigrams_stats_add[full_name] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('artykuł:brev & .:interp', 83761),\n",
       " ('ustęp:brev & .:interp', 53319),\n",
       " ('pozycja:brev & .:interp', 45216),\n",
       " (',:interp & pozycja:brev', 43166),\n",
       " ('.:interp & 1:adj', 39924),\n",
       " ('-:interp & -:interp', 36548),\n",
       " ('rok:brev & .:interp', 33025),\n",
       " ('w:prep & artykuł:brev', 32037),\n",
       " (',:interp & o:prep', 29913),\n",
       " ('o:prep & który:adj', 28656)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(bigrams_stats.items(), key=lambda item: (-item[1], item[0]))[:10] # posortowane alfabetycznie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('artykuł:brev & .:interp', 83761),\n",
       " ('ustęp:brev & .:interp', 53319),\n",
       " ('pozycja:brev & .:interp', 45216),\n",
       " (',:interp & pozycja:brev', 43166),\n",
       " ('.:interp & 1:adj', 39924),\n",
       " ('-:interp & -:interp', 36548),\n",
       " ('rok:brev & .:interp', 33025),\n",
       " ('w:prep & artykuł:brev', 32037),\n",
       " (',:interp & o:prep', 29913),\n",
       " ('o:prep & który:adj', 28656)]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Zwraca dokładnie to samo.\n",
    "sorted(bigrams_stats_add.items(), key=lambda item: (-item[1], item[0]))[:10] # posortowane alfabetycznie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.:interp', 457513),\n",
       " (',:interp', 343058),\n",
       " ('w:prep', 202690),\n",
       " ('):interp', 102195),\n",
       " ('i:conj', 90002),\n",
       " ('z:prep', 87985),\n",
       " ('artykuł:brev', 83766),\n",
       " ('1:adj', 74275),\n",
       " ('o:prep', 64714),\n",
       " ('-:interp', 61832)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(single_stats.items(), key=lambda item: (-item[1], item[0]))[:10] # posortowane alfabetycznie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Discard bigrams containing characters other than letters. Make sure that you discard the invalid entries after computing the bigram counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_stats_clean = bigrams_stats\n",
    "for bigram, count in list(bigrams_stats.items()):\n",
    "    # print(bigram)\n",
    "    w1, w2 = bigram.split(\" & \")\n",
    "    lem1 = w1.split(\":\")[0]\n",
    "    lem2 = w2.split(\":\")[0]\n",
    "    found1 = regex.findall(r'\\p{L}+', lem1, flags=regex.IGNORECASE)\n",
    "    found2 = regex.findall(r'\\p{L}+', lem2, flags=regex.IGNORECASE)\n",
    "\n",
    "    if not found1 or not found2:\n",
    "        del bigrams_stats_clean[bigram]\n",
    "\n",
    "single_stats_clean = single_stats\n",
    "for single, count in list(single_stats.items()):\n",
    "    lem = single.split(\":\")[0]\n",
    "    found = regex.findall(r'\\p{L}+', lem, flags=regex.IGNORECASE)\n",
    "    if not found:\n",
    "        del single_stats_clean[single]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przywrócenie spacji między bigramami\n",
    "# tmp = Counter()\n",
    "# for bigram, count in bigrams_stats_clean.items():\n",
    "#     tmp[bigram.replace(\" & \", \" \")] = count\n",
    "# bigrams_stats_clean = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('w:prep & artykuł:brev', 32037),\n",
       " ('o:prep & który:adj', 28656),\n",
       " ('który:adj & mowa:subst', 28538),\n",
       " ('mowa:subst & w:prep', 28473),\n",
       " ('w:prep & ustęp:brev', 23536),\n",
       " ('z:prep & dzień:subst', 11360),\n",
       " ('otrzymywać:fin & brzmienie:subst', 10535),\n",
       " ('określić:ppas & w:prep', 9686),\n",
       " ('do:prep & sprawa:subst', 8718),\n",
       " ('ustawa:subst & z:prep', 8625)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(bigrams_stats_clean.items(), key=lambda item: (-item[1], item[0]))[:10] # posortowane alfabetycznie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('w:prep', 202690),\n",
       " ('i:conj', 90002),\n",
       " ('z:prep', 87985),\n",
       " ('artykuł:brev', 83766),\n",
       " ('o:prep', 64714),\n",
       " ('do:prep', 60758),\n",
       " ('ustęp:brev', 53338),\n",
       " ('na:prep', 50647),\n",
       " ('który:adj', 49380),\n",
       " ('się:qub', 45888)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(single_stats_clean.items(), key=lambda item: (-item[1], item[0]))[:10] # posortowane alfabetycznie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Compute LLR statistic for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def H(counts: List[int]) -> float:\n",
    "def H(counts) -> float:\n",
    "    try:\n",
    "        total = float(sum(counts))\n",
    "        # print(total)\n",
    "        # Note tricky way to avoid 0*log(0)\n",
    "        return -sum([k/total * math.log(k/total + (k==0)) for k in counts])\n",
    "        # return -sum([k * math.log(k / total + (k==0)) for k in counts])\n",
    "\n",
    "    except ValueError:\n",
    "        # pass\n",
    "        print(counts)\n",
    "        total = float(sum(counts))\n",
    "        print(total)\n",
    "        for k in counts:\n",
    "            print()\n",
    "            print(k/total)\n",
    "            print(k/total + (k==0))\n",
    "            print()\n",
    "\n",
    "\n",
    "def llr(a: int, b: int, ab_count: int, total_tokens: int) -> float:\n",
    "    k11 = float(ab_count) # count of bigrams (a,b)\n",
    "    # k12 = token_counts[b] - ab_count\n",
    "    k12 = float(b - ab_count)\n",
    "    # k21 = token_counts[a] - ab_count\n",
    "    k21 = float(a - ab_count)\n",
    "    k22 = float(total_tokens - k12 - k21 - k11)\n",
    "    \n",
    "    return 2 * (H([k11 + k12, k21 + k22]) +\n",
    "                H([k11 + k21, k12 + k22]) -\n",
    "                H([k11, k12, k21, k22]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bigrams_stats_count = float(sum(bigrams_stats_clean.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "llr_score = {}\n",
    "\n",
    "for pair, count in bigrams_stats_clean.items():\n",
    "    w = pair.split(\" & \")\n",
    "    # print(w[0], w[1])\n",
    "    llr_score[pair] = llr(single_stats_clean[w[0]], single_stats_clean[w[1]], count, all_bigrams_stats_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('który:adj & mowa:subst', 0.08936695719267704),\n",
       " ('o:prep & który:adj', 0.05900771544156197),\n",
       " ('mowa:subst & w:prep', 0.053860289864104516),\n",
       " ('otrzymywać:fin & brzmienie:subst', 0.03994394235769046),\n",
       " ('w:prep & artykuł:brev', 0.024475458879820056),\n",
       " ('minister:subst & właściwy:adj', 0.024415048896080524),\n",
       " ('dodawać:fin & się:qub', 0.02405706905647026),\n",
       " ('w:prep & ustęp:brev', 0.020420849637738492),\n",
       " ('stosować:fin & się:qub', 0.01905141014777051),\n",
       " ('droga:subst & rozporządzenie:subst', 0.018643621599944822)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(llr_score.items(), key=lambda item: (-item[1], item[0]))[:10] # posortowane alfabetycznie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_results = pd.DataFrame({\n",
    "    \"bigram\": bigrams_stats_clean.keys(),\n",
    "    \"count\": bigrams_stats_clean.values(),\n",
    "    \"llr\": [llr_score[pair] for pair, _ in bigrams_stats_clean.items()]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bigrams_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18424/2919994666.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbigrams_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'llr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'bigrams_results' is not defined"
     ]
    }
   ],
   "source": [
    "bigrams_stats_clean.sort_values('llr', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Partition the entries based on the syntactic categories of the words, i.e. all bigrams having the form of w1:adj w2:subst should be placed in one partition (the order of the words may not be changed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_bigrams(bigram):\n",
    "    l1, l2 = bigram.split(\" & \")\n",
    "    morph_cat1 = l1.split(\":\")[1]\n",
    "    morph_cat2 = l2.split(\":\")[1]\n",
    "    \n",
    "    return morph_cat1, morph_cat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_results[\"partition\"] = [partition_bigrams(bigram) for bigram, _ in bigrams_stats_clean.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>count</th>\n",
       "      <th>llr</th>\n",
       "      <th>partition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>który:adj &amp; mowa:subst</td>\n",
       "      <td>28538</td>\n",
       "      <td>8.936696e-02</td>\n",
       "      <td>(adj, subst)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>o:prep &amp; który:adj</td>\n",
       "      <td>28656</td>\n",
       "      <td>5.900772e-02</td>\n",
       "      <td>(prep, adj)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>mowa:subst &amp; w:prep</td>\n",
       "      <td>28473</td>\n",
       "      <td>5.386029e-02</td>\n",
       "      <td>(subst, prep)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>otrzymywać:fin &amp; brzmienie:subst</td>\n",
       "      <td>10535</td>\n",
       "      <td>3.994394e-02</td>\n",
       "      <td>(fin, subst)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>w:prep &amp; artykuł:brev</td>\n",
       "      <td>32037</td>\n",
       "      <td>2.447546e-02</td>\n",
       "      <td>(prep, brev)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194344</th>\n",
       "      <td>artystyczny:adj &amp; otrzymywać:fin</td>\n",
       "      <td>1</td>\n",
       "      <td>2.504941e-15</td>\n",
       "      <td>(adj, fin)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184212</th>\n",
       "      <td>przedmiot:subst &amp; przekazywać:fin</td>\n",
       "      <td>1</td>\n",
       "      <td>3.781697e-16</td>\n",
       "      <td>(subst, fin)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346162</th>\n",
       "      <td>z:prep &amp; urządzić:ger</td>\n",
       "      <td>2</td>\n",
       "      <td>3.330669e-16</td>\n",
       "      <td>(prep, ger)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141657</th>\n",
       "      <td>uciążliwy:adj &amp; z:prep</td>\n",
       "      <td>2</td>\n",
       "      <td>3.330669e-16</td>\n",
       "      <td>(adj, prep)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59196</th>\n",
       "      <td>granica:subst &amp; on:ppron3</td>\n",
       "      <td>19</td>\n",
       "      <td>1.249001e-16</td>\n",
       "      <td>(subst, ppron3)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>369956 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   bigram  count           llr  \\\n",
       "133                który:adj & mowa:subst  28538  8.936696e-02   \n",
       "132                    o:prep & który:adj  28656  5.900772e-02   \n",
       "134                   mowa:subst & w:prep  28473  5.386029e-02   \n",
       "65       otrzymywać:fin & brzmienie:subst  10535  3.994394e-02   \n",
       "19                  w:prep & artykuł:brev  32037  2.447546e-02   \n",
       "...                                   ...    ...           ...   \n",
       "194344   artystyczny:adj & otrzymywać:fin      1  2.504941e-15   \n",
       "184212  przedmiot:subst & przekazywać:fin      1  3.781697e-16   \n",
       "346162              z:prep & urządzić:ger      2  3.330669e-16   \n",
       "141657             uciążliwy:adj & z:prep      2  3.330669e-16   \n",
       "59196           granica:subst & on:ppron3     19  1.249001e-16   \n",
       "\n",
       "              partition  \n",
       "133        (adj, subst)  \n",
       "132         (prep, adj)  \n",
       "134       (subst, prep)  \n",
       "65         (fin, subst)  \n",
       "19         (prep, brev)  \n",
       "...                 ...  \n",
       "194344       (adj, fin)  \n",
       "184212     (subst, fin)  \n",
       "346162      (prep, ger)  \n",
       "141657      (adj, prep)  \n",
       "59196   (subst, ppron3)  \n",
       "\n",
       "[369956 rows x 4 columns]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams_results.sort_values('llr', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Select the 10 largest partitions (partitions with the largest number of entries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "partition\n",
       "(prep, subst)     326367\n",
       "(subst, subst)    290516\n",
       "(subst, adj)      273693\n",
       "(adj, subst)      187748\n",
       "(subst, prep)     176856\n",
       "(subst, conj)      86070\n",
       "(conj, subst)      85044\n",
       "(prep, adj)        79189\n",
       "(ger, subst)       77146\n",
       "(prep, brev)       66991\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/39922986/pandas-group-by-and-sum\n",
    "# 1. bigrams_results.groupby(\"partition\")[\"count\"]\n",
    "# 2. bigrams_results.groupby(\"partition\")[\"count\"].sum()\n",
    "# 3. bigrams_results.groupby(\"partition\")[\"count\"].sum().sort_values(ascending=False)\n",
    "best_10 = bigrams_results.groupby(\"partition\")[\"count\"].sum().sort_values(ascending=False).head(10)\n",
    "best_10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Use the computed LLR measure to select 5 bigrams for each of the largest categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition: prep subst:\n",
      "\t 1. do sprawa, LLR: 0.016347886261125877, Count: 8718\n",
      "\t 2. na podstawa, LLR: 0.016321460001314902, Count: 6681\n",
      "\t 3. z dzień, LLR: 0.015554089587361264, Count: 11360\n",
      "\t 4. w droga, LLR: 0.01133295526462319, Count: 7128\n",
      "\t 5. od dzień, LLR: 0.01058630311144651, Count: 5324\n",
      "\n",
      "Partition: subst subst:\n",
      "\t 1. droga rozporządzenie, LLR: 0.018643621599944822, Count: 4748\n",
      "\t 2. skarb państwo, LLR: 0.007929649586206275, Count: 1821\n",
      "\t 3. rada minister, LLR: 0.0052964763281811295, Count: 2265\n",
      "\t 4. terytorium rzeczpospolita, LLR: 0.005027677559428588, Count: 1224\n",
      "\t 5. ochrona środowisko, LLR: 0.0049948130724266, Count: 1572\n",
      "\n",
      "Partition: subst adj:\n",
      "\t 1. minister właściwy, LLR: 0.024415048896080524, Count: 7933\n",
      "\t 2. rzeczpospolita polski, LLR: 0.01621683128496678, Count: 3816\n",
      "\t 3. jednostka organizacyjny, LLR: 0.00862785521862549, Count: 2252\n",
      "\t 4. samorząd terytorialny, LLR: 0.008355100931056653, Count: 1675\n",
      "\t 5. produkt leczniczy, LLR: 0.0076843470261675345, Count: 1738\n",
      "\n",
      "Partition: adj subst:\n",
      "\t 1. który mowa, LLR: 0.08936695719267704, Count: 28538\n",
      "\t 2. niniejszy ustawa, LLR: 0.007163789601399559, Count: 2364\n",
      "\t 3. następujący zmiana, LLR: 0.006197481855211524, Count: 1622\n",
      "\t 4. odrębny przepis, LLR: 0.004220875679988259, Count: 1449\n",
      "\t 5. walny zgromadzenie, LLR: 0.0034371007912226276, Count: 598\n",
      "\n",
      "Partition: subst prep:\n",
      "\t 1. mowa w, LLR: 0.053860289864104516, Count: 28473\n",
      "\t 2. ustawa z, LLR: 0.010519206248382373, Count: 8625\n",
      "\t 3. miesiąc od, LLR: 0.003732318331434531, Count: 1581\n",
      "\t 4. nadzór nad, LLR: 0.0036720923202311906, Count: 862\n",
      "\t 5. wniosek o, LLR: 0.003425791023360769, Count: 2619\n",
      "\n",
      "Partition: subst conj:\n",
      "\t 1. przecinek i, LLR: 0.0012228993590459591, Count: 645\n",
      "\t 2. wolność albo, LLR: 0.0007237503194452433, Count: 323\n",
      "\t 3. całość lub, LLR: 0.0007139016654658659, Count: 377\n",
      "\t 4. mowa i, LLR: 0.0006249432965663715, Count: 18\n",
      "\t 5. imię i, LLR: 0.0005608908502924836, Count: 480\n",
      "\n",
      "Partition: conj subst:\n",
      "\t 1. i tryb, LLR: 0.001367534365374956, Count: 1264\n",
      "\t 2. i nazwisko, LLR: 0.0006647299949201213, Count: 463\n",
      "\t 3. i dzień, LLR: 0.0006181169086088012, Count: 13\n",
      "\t 4. i usługa, LLR: 0.0005451244067571914, Count: 642\n",
      "\t 5. i wychowanie, LLR: 0.0004827850788347021, Count: 272\n",
      "\n",
      "Partition: prep adj:\n",
      "\t 1. o który, LLR: 0.05900771544156197, Count: 28656\n",
      "\t 2. w właściwy, LLR: 0.0005177468889721037, Count: 104\n",
      "\t 3. za każdy, LLR: 0.0004573607963855586, Count: 267\n",
      "\t 4. w ten, LLR: 0.0004183037503454612, Count: 2782\n",
      "\t 5. przez ten, LLR: 0.0003504776251552211, Count: 653\n",
      "\n",
      "Partition: ger subst:\n",
      "\t 1. zasięgnąć opinia, LLR: 0.004082193088855341, Count: 787\n",
      "\t 2. pozbawić wolność, LLR: 0.004067311534817611, Count: 797\n",
      "\t 3. wykonywać zawód, LLR: 0.0019779109289990923, Count: 561\n",
      "\t 4. zawrzeć umowa, LLR: 0.0018454925807922379, Count: 507\n",
      "\t 5. wszcząć postępowanie, LLR: 0.0018150307897788348, Count: 500\n",
      "\n",
      "Partition: prep brev:\n",
      "\t 1. w artykuł, LLR: 0.024475458879820056, Count: 32037\n",
      "\t 2. w ustęp, LLR: 0.020420849637738492, Count: 23536\n",
      "\t 3. z późniejszy, LLR: 0.0025359959267807763, Count: 1017\n",
      "\t 4. w numer, LLR: 0.002456388400017273, Count: 5\n",
      "\t 5. w pozycja, LLR: 0.0022378836742990016, Count: 74\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sorted_by_llr = bigrams_results.sort_values('llr', ascending=False)\n",
    "\n",
    "for category, count in best_10.iteritems():\n",
    "    tmp_cnt = 0\n",
    "    print(\"Partition: \" + \" \".join(category) + \":\")\n",
    "    for index, data in sorted_by_llr.iterrows():\n",
    "        if category == data[\"partition\"]:\n",
    "            w1, w2 = data[\"bigram\"].split(\" & \")\n",
    "            bigram_str = w1.split(\":\")[0] + \" \" + w2.split(\":\")[0]\n",
    "            print(f\"\\t {tmp_cnt+1}. {bigram_str}, LLR: {data['llr']}, Count: {data['count']}\")\n",
    "            tmp_cnt += 1\n",
    "        if tmp_cnt == 5:\n",
    "            print()\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Using the results from the previous step answer the following questions:\n",
    "1. What types of bigrams have been found?\n",
    "2. Which of the category-pairs indicate valuable multiword expressions? Do they have anything in common?\n",
    "3. Which signal: LLR score or syntactic category is more useful for determining genuine multiword expressions?\n",
    "4. Can you describe a different use-case where the morphosyntactic category is useful for resolving a real-world problem?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. To zależy od grupy ale generalnie:\n",
    "    - jest dużo grup z przyimkami (z, w, na itd.),\n",
    "    - jest trochę grup ze spójnikami (i, lub itd.),\n",
    "    - jest grupa zawierająca elementy które często występują razem i nazwy własne (urząd patentowy, wzór użytkowy, znak towarowy) - tu by PMI dobrze weszło,\n",
    "    - jest grupa czasownik + rzeczownik\n",
    "\n",
    "2. Raczej nie te które zawierają przyimki. Grupy które zawierają nazwy własne lub czasownik + rzeczownik mogą być przydatne. Czyli to będą subst adj, adj subst, subst subst, ger subst.\n",
    "\n",
    "3. Z tego co wychodziło w lab4 oraz tutaj, wysokie LLR mają bigramy ze spójnikami i przyimkami, a nas generalnie to nie interesuje. Podział na grupy pozwala takie lementy wyeliminować i niektóre grupy dają fajne wyniki, ale z drugiej strony często jest tam niski LLR, a niski LLR może świadczyć o tym, że te słowa nie są zbyt często obok siebie. Więc raczej to zależy albo można używać obu naraz.\n",
    "\n",
    "4. Może do przygotowania jakichś danych (np. do nauki jakichś narzędzi ML) gdzie nie warto brać pod uwagę spójników i przyimków. \n",
    "Może też indeksowanie po nazwach. Wtedy spójniki i przyimki na pewno są niepotrzebne.\n",
    "Nie wiem czy to by się wliczało, ale przy elasticu była mowa o wyszukiwaniu, gdzie raczej z fraz wyrzuca się spójniki i przyimki, więc może tam. \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "da09b68f613570449f88c91791aa0345a4974afa8206cbbcee6cca73a7d2ca93"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 32-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
